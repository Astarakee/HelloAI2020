{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tumor in the Lung PET-CT data set was segmented and will be quantified in the following steps.\n",
    "# The purpose is to quantify the tumor mass into mineable data by extracting features from the tumor.\n",
    "# The definitions of some of the features were provided in the supplementary document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from radiomics import firstorder, glcm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the images along with their segmentation masks\n",
    "\n",
    "CT_Image = sitk.ReadImage('Data/CT_Data.nii.gz')\n",
    "CT_Mask = sitk.ReadImage('Data/CT_Mask.nii.gz')\n",
    "\n",
    "PET_Image = sitk.ReadImage('Data/PET_Data.nii.gz')\n",
    "PET_Mask = sitk.ReadImage('Data/PET_Mask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Order Statistics Features from CT image\n",
    "\n",
    "FOS_CT = firstorder.RadiomicsFirstOrder(CT_Image, CT_Mask)\n",
    "FOS_CT.enableAllFeatures()\n",
    "FOS_CT_Features = FOS_CT.execute()\n",
    "for (key, val) in six.iteritems(FOS_CT_Features):\n",
    "  print('The value of the feature  ', key, ' is equal to:', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Order Statistics Features from PET image\n",
    "\n",
    "FOS_PET = firstorder.RadiomicsFirstOrder(PET_Image, PET_Mask)\n",
    "FOS_PET.enableAllFeatures()\n",
    "FOS_PET_Features = FOS_PET.execute()\n",
    "for (key, val) in six.iteritems(FOS_PET_Features):\n",
    "  print('The value of the feature  ', key, ' is equal to:', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can you interprete these results?\n",
    "\n",
    "print(\"The average intensity of the tumor in CT image is:\", FOS_CT_Features[\"Mean\"])\n",
    "print(\"The average intensity of the tumor in PET image is:\", FOS_PET_Features[\"Mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textural Features (Gray Level Co-occurrence Matrix) for CT image\n",
    "\n",
    "CT_GLCM = glcm.RadiomicsGLCM(CT_Image, CT_Mask)\n",
    "CT_GLCM.enableAllFeatures()\n",
    "CT_GLCM_Features = CT_GLCM.execute()\n",
    "for (key, val) in six.iteritems(CT_GLCM_Features):\n",
    "  print('The value of the feature  ', key, ' is equal to:', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textural Features (Gray Level Co-occurrence Matrix) for PET image\n",
    "\n",
    "PET_GLCM = glcm.RadiomicsGLCM(PET_Image, PET_Mask)\n",
    "PET_GLCM.enableAllFeatures()\n",
    "PET_GLCM_Features = PET_GLCM.execute()\n",
    "for (key, val) in six.iteritems(PET_GLCM_Features):\n",
    "  print('The value of the feature  ', key, ' is equal to:', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2) Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The tumors from 31 PET-CT images were already segmented and first order as well as textural features were already extracted and saved in excel files. We already know which of the patients survived or not. From the machine learning perspective, that means we know the outcome labels.  Now, with the extracted features and the outcome labels, we can train a classifier to predict the survival status. For this task, we will use Support Vector Machine as a learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Feature set\n",
    "\n",
    "ALL_CT = pd.read_csv('Data/CT_All.csv', header=None) \n",
    "ALL_PET = pd.read_csv('Data/PET_ALL.csv', header=None) \n",
    "Labels = pd.read_csv('Data/Labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the feature set\n",
    "\n",
    "X_ALL_CT = ALL_CT.values[:, :]\n",
    "X_ALL_CT = (X_ALL_CT-np.mean(X_ALL_CT))/np.std(X_ALL_CT)\n",
    "\n",
    "\n",
    "X_ALL_PET = ALL_PET.values[:,:]\n",
    "X_ALL_PET = (X_ALL_PET-np.mean(X_ALL_PET))/np.std(X_ALL_PET)\n",
    "\n",
    "y_ALL = Labels.values[:,:]  # Outcome Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the CT feature set into train and test sets\n",
    "\n",
    "X_train_CT, X_test_CT, y_train_CT, y_test_CT = train_test_split(X_ALL_CT, y_ALL, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a classifier model with CT features\n",
    "\n",
    "Model_CT = SVC(gamma='auto')\n",
    "Model_CT.set_params(kernel='rbf').fit(X_train_CT,y_train_CT.ravel())  \n",
    "\n",
    "y_pred_CT = Model_CT.predict(X_test_CT) \n",
    "FOS_CT_Acc = metrics.accuracy_score(y_test_CT,y_pred_CT)\n",
    "print('Accuracy Score:',metrics.accuracy_score(y_test_CT,y_pred_CT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the PET feature set into train and test sets\n",
    "\n",
    "X_train_PET, X_test_PET, y_train_PET, y_test_PET = train_test_split(X_ALL_PET, y_ALL, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a classifier model with PET features\n",
    "\n",
    "Model_PET = SVC(gamma='auto') \n",
    "Model_PET.set_params(kernel='rbf').fit(X_train_PET,y_train_PET.ravel())  \n",
    "\n",
    "y_pred_PET = Model_PET.predict(X_test_PET) \n",
    "FOS_PET_Acc = metrics.accuracy_score(y_test_PET, y_pred_PET)\n",
    "print('Accuracy Score:',metrics.accuracy_score(y_test_PET,y_pred_PET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Which feature set have more prediction power? Can you explain?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
